{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 20:21:49.073351: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-05 20:21:49.073381: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-05 20:21:49.073412: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-05 20:21:49.079190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-05 20:21:49.993535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from find_image import FindImage\n",
    "import botocore\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cpu_compiler', '/usr/lib/llvm-16/bin/clang'),\n",
       "             ('cuda_compute_capabilities',\n",
       "              ['sm_35', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']),\n",
       "             ('cuda_version', '11.8'),\n",
       "             ('cudnn_version', '8'),\n",
       "             ('is_cuda_build', True),\n",
       "             ('is_rocm_build', False),\n",
       "             ('is_tensorrt_build', True)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sysconfig.get_build_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 22:57:43.868240: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-04 22:57:43.868892: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/patrick/SPTECH/TCC/grupo11-4cco-tcc/src/inteligencia_artificial/POC_recognator.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/patrick/SPTECH/TCC/grupo11-4cco-tcc/src/inteligencia_artificial/POC_recognator.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Loading model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/patrick/SPTECH/TCC/grupo11-4cco-tcc/src/inteligencia_artificial/POC_recognator.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(os\u001b[39m.\u001b[39;49mgetenv(\u001b[39m'\u001b[39;49m\u001b[39mMODEL_PATH\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/legacy/save.py:239\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39;49mload(\n\u001b[1;32m    240\u001b[0m         filepath_str, \u001b[39mcompile\u001b[39;49m, options\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m h5py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/legacy/saved_model/load.py:145\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    142\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\n\u001b[1;32m    143\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrying to load ShardedVariables\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m     )\n\u001b[0;32m--> 145\u001b[0m     loaded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload_partial(\n\u001b[1;32m    146\u001b[0m         path, nodes_to_load, options\u001b[39m=\u001b[39;49moptions\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    149\u001b[0m \u001b[39m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m keras_loader\u001b[39m.\u001b[39mfinalize_objects()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:988\u001b[0m, in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39minit_scope():\n\u001b[1;32m    987\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 988\u001b[0m     loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[1;32m    989\u001b[0m                     ckpt_options, options, filters)\n\u001b[1;32m    990\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    991\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    992\u001b[0m         \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    994\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    995\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:202\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m# Order all nodes or filtered nodes using the dependencies.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ordered_node_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_ordered_node_ids()\n\u001b[0;32m--> 202\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_all()\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_options\u001b[39m.\u001b[39mexperimental_skip_checkpoint:\n\u001b[1;32m    205\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restore_checkpoint()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:299\u001b[0m, in \u001b[0;36mLoader._load_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_all\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    298\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Loads all nodes and functions from the SavedModel and their edges.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_nodes()\n\u001b[1;32m    300\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_edges()\n\u001b[1;32m    302\u001b[0m   \u001b[39m# Set up concrete functions that aren't part of the object graph\u001b[39;00m\n\u001b[1;32m    303\u001b[0m   \u001b[39m# (e.g. gradient functions)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:514\u001b[0m, in \u001b[0;36mLoader._load_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m   node_setters[slot_variable_proto\u001b[39m.\u001b[39mslot_variable_node_id] \u001b[39m=\u001b[39m \u001b[39msetattr\u001b[39m\n\u001b[1;32m    513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 514\u001b[0m   node, setter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recreate(proto, node_id, nodes)\n\u001b[1;32m    515\u001b[0m   nodes[node_id] \u001b[39m=\u001b[39m node\n\u001b[1;32m    516\u001b[0m   node_setters[node_id] \u001b[39m=\u001b[39m setter\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:633\u001b[0m, in \u001b[0;36mLoader._recreate\u001b[0;34m(self, proto, node_id, nodes)\u001b[0m\n\u001b[1;32m    631\u001b[0m   \u001b[39mreturn\u001b[39;00m obj, setter\n\u001b[1;32m    632\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recreate_default(proto, node_id, dependencies)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:652\u001b[0m, in \u001b[0;36mLoader._recreate_default\u001b[0;34m(self, proto, node_id, deps)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m kind \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m factory:\n\u001b[1;32m    650\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown SavedObject type: \u001b[39m\u001b[39m{\u001b[39;00mkind\u001b[39m}\u001b[39;00m\u001b[39m. Expected one of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    651\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(factory\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 652\u001b[0m \u001b[39mreturn\u001b[39;00m factory[kind]()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:707\u001b[0m, in \u001b[0;36mLoader._recreate_bare_concrete_function\u001b[0;34m(self, proto, dependencies)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recreate_bare_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, proto, dependencies):\n\u001b[1;32m    705\u001b[0m   fn \u001b[39m=\u001b[39m function_deserialization\u001b[39m.\u001b[39msetup_bare_concrete_function(\n\u001b[1;32m    706\u001b[0m       proto, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_functions)\n\u001b[0;32m--> 707\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_function_captures(proto\u001b[39m.\u001b[39;49mconcrete_function_name, dependencies)\n\u001b[1;32m    708\u001b[0m   \u001b[39mreturn\u001b[39;00m fn, \u001b[39msetattr\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:382\u001b[0m, in \u001b[0;36mLoader._setup_function_captures\u001b[0;34m(self, concrete_function_name, nodes)\u001b[0m\n\u001b[1;32m    380\u001b[0m proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proto\u001b[39m.\u001b[39mconcrete_functions[concrete_function_name]\n\u001b[1;32m    381\u001b[0m inputs \u001b[39m=\u001b[39m [nodes[node_id] \u001b[39mfor\u001b[39;00m node_id \u001b[39min\u001b[39;00m proto\u001b[39m.\u001b[39mbound_inputs]\n\u001b[0;32m--> 382\u001b[0m restore_captures\u001b[39m.\u001b[39;49mrestore_captures(concrete_function, inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/capture/restore_captures.py:121\u001b[0m, in \u001b[0;36mrestore_captures\u001b[0;34m(concrete_function, inputs)\u001b[0m\n\u001b[1;32m    118\u001b[0m       handle_data_util\u001b[39m.\u001b[39mcopy_handle_data(handle, internal_capture)\n\u001b[1;32m    119\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[39m# TODO(b/213451747): Remove need to call copy_handle_data\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     handle_data_util\u001b[39m.\u001b[39;49mcopy_handle_data(bound_input, internal_capture)\n\u001b[1;32m    122\u001b[0m \u001b[39m# Setting \"captures\" first means \"capture\" won't create a new\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m# placeholder for this input.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mcapture(bound_input)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/handle_data_util.py:61\u001b[0m, in \u001b[0;36mcopy_handle_data\u001b[0;34m(source_t, target_t)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m (target_t\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mresource \u001b[39mor\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     target_t\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mvariant):\n\u001b[1;32m     60\u001b[0m   handle_data \u001b[39m=\u001b[39m get_handle_data(source_t)\n\u001b[0;32m---> 61\u001b[0m   set_handle_data(target_t, handle_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/handle_data_util.py:64\u001b[0m, in \u001b[0;36mset_handle_data\u001b[0;34m(target_t, handle_data)\u001b[0m\n\u001b[1;32m     60\u001b[0m     handle_data \u001b[39m=\u001b[39m get_handle_data(source_t)\n\u001b[1;32m     61\u001b[0m     set_handle_data(target_t, handle_data)\n\u001b[0;32m---> 64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_handle_data\u001b[39m(target_t, handle_data):\n\u001b[1;32m     65\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Sets handle data on the giver tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     67\u001b[0m       handle_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m       \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m handle_data\u001b[39m.\u001b[39mis_set\n\u001b[1;32m     69\u001b[0m       \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m handle_data\u001b[39m.\u001b[39mshape_and_type\n\u001b[1;32m     70\u001b[0m   ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loading model\n",
    "loaded_model = tf.keras.models.load_model(os.getenv('MODEL_PATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class_names.json', 'r') as file:\n",
    "    class_names_generated = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pet():\n",
    "  # Carregando e redimensionando a imagem\n",
    "  img = image.load_img(os.getenv('PATH_DOWNLOADED_IMG'), target_size=(224, 224))\n",
    "  img_array = image.img_to_array(img)\n",
    "  img_array = np.expand_dims(img_array, axis=0)\n",
    "  img_array /= 255.0  # Normalização\n",
    "\n",
    "  # Fazendo a previsão\n",
    "  prediction = loaded_model.predict(img_array)\n",
    "  \n",
    "  # Obtendo a classe prevista\n",
    "  predicted_class_index = np.argmax(prediction)\n",
    "\n",
    "  # Obtendo o nome da classe\n",
    "  predicted_class = class_names_generated[f\"{predicted_class_index}\"]\n",
    "\n",
    "\n",
    "  # Imprimindo a classe prevista\n",
    "  print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/patrick/SPTECH/TCC/grupo11-4cco-tcc/src/inteligencia_artificial/imgs_test/dog1.jpg\n",
      "Arquivo baixado com sucesso.\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "dog1\n"
     ]
    }
   ],
   "source": [
    "s3 = FindImage(flag=True, bucket_name=os.getenv(\"BUCKET_S3\"), resource_name=\"s3\")\n",
    "\n",
    "try:\n",
    "    print(os.getenv('PATH_DOWNLOADED_IMG'))\n",
    "    #s3.download(os.getenv('FILE_KEY'), os.getenv('PATH_DOWNLOADED_IMG'))\n",
    "    print(f\"Arquivo baixado com sucesso.\")\n",
    "    match_pet()\n",
    "except botocore.exceptions.NoCredentialsError:\n",
    "    print(\"Credenciais não encontradas ou inválidas.\")\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == \"404\":\n",
    "        print(\"O arquivo não foi encontrado no bucket.\")\n",
    "    else:\n",
    "        print(\"Erro desconhecido ao baixar o arquivo:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
